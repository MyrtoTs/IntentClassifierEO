{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install peft\n",
        "%pip install sentence-transformers"
      ],
      "metadata": {
        "id": "21sxdjK7z0yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb6AT26BytZk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel, PeftConfig, get_peft_model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "s_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "example = \"Give me 100 images similar to this one\"\n",
        "e = ''.join([i for i in example if not i.isdigit()] )\n",
        "\n",
        "def sbi(request, threshold = 0.7):\n",
        "  t = ''.join([i for i in request if not i.isdigit()] )\n",
        "  c = cosine_similarity(s_model.encode(e).reshape(1,-1),(s_model.encode(t).reshape(1,-1)))\n",
        "  if c>threshold:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "model_id = \"myrtotsok/distilbert-base-uncased-EO-intent-classifier-6\"\n",
        "\n",
        "# load peft model from hub for inference\n",
        "config = PeftConfig.from_pretrained(model_id)\n",
        "\n",
        "# define label maps\n",
        "id2label = {0: 'binary visual question answering', 1:'image search by text',\n",
        "            2:'count/extract/segment'}\n",
        "\n",
        "label2id = {'binary visual question answering':0, 'image search by text':1,\n",
        "            'count/extract/segment':2 }\n",
        "\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    config.base_model_name_or_path, num_labels=3, id2label=id2label, label2id=label2id\n",
        ")\n",
        "clf_tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "clf_model = PeftModel.from_pretrained(inference_model, model_id)\n",
        "\n",
        "def classifier(request):\n",
        "    inputs = clf_tokenizer.encode(request, return_tensors=\"pt\")\n",
        "    logits = clf_model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "    return predictions\n",
        "\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n",
        "\n",
        "def geospatial(request):\n",
        "  gsp = False\n",
        "  ner_results = nlp(request)\n",
        "  for result in ner_results:\n",
        "    if result['entity']=='B-LOC':\n",
        "      gsp = True\n",
        "      break\n",
        "  return gsp\n",
        "\n",
        "def intent_classification(request):\n",
        "  label = []\n",
        "  intent_labels = ['binary visual question answering', 'image search by text',\n",
        "            'count/extract/segment', 'search by image', 'geospatial']\n",
        "  intent_vector = np.zeros(5, dtype= int)\n",
        "\n",
        "  # NOTE : intent_vector can be used for integration in API\n",
        "\n",
        "  if not sbi(request):\n",
        "    intent_vector[classifier(request)]=1\n",
        "  else:\n",
        "    intent_vector[3] = 1\n",
        "\n",
        "  if geospatial(request):\n",
        "    intent_vector[4]=1\n",
        "\n",
        "  label_indeces = np.where((intent_vector) == 1)[0].tolist()\n",
        "  for l in label_indeces:\n",
        "    label.append(intent_labels[l])\n",
        "\n",
        "  return ', '.join(label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_classification('Show me all images with ships, within 100 km from the port of Genoa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yth9jgw90B_G",
        "outputId": "ec80c80a-0060-483a-e68b-3c67a7c9ed51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'image search by text, geospatial'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}